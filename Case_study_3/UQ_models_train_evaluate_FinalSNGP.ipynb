{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747cb51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5' \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from progressbar import ProgressBar\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, Reshape, Layer\n",
    "from tensorflow.keras.layers import Dropout, ReLU\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# for SNGP\n",
    "import official.nlp.modeling.layers as nlp_layers\n",
    "\n",
    "# for SNGP\n",
    "import gpflow\n",
    "import gpflux\n",
    "from gpflow.config import default_float\n",
    "from lib.spectral_normalization import SpectralNormalization\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593d4266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unit5_win1_str1_smp500.npz', 'Unit2_win1_str1_smp500.npz', 'Unit16_win1_str1_smp500.npz', 'Unit10_win1_str1_smp500.npz', 'Unit18_win1_str1_smp500.npz', 'Unit20_win1_str1_smp500.npz', 'Unit11_win1_str1_smp500.npz', 'Unit14_win1_str1_smp500.npz', 'Unit15_win1_str1_smp500.npz']\n",
      "['Unit20_win1_str1_smp500.npz', 'Unit5_win1_str1_smp500.npz', 'Unit18_win1_str1_smp500.npz', 'Unit16_win1_str1_smp500.npz', 'Unit10_win1_str1_smp500.npz', 'Unit2_win1_str1_smp500.npz']\n"
     ]
    }
   ],
   "source": [
    "mypath = 'N-CMAPSS_DL/N-CMAPSS/Samples_whole/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(onlyfiles)\n",
    "\n",
    "train_units = [2,5,10,16,18,20]\n",
    "test_units = [11,14,15]\n",
    "\n",
    "test_files = [[f for f in onlyfiles if str(test_units[j]) in f ] for j in range(len(test_units))]\n",
    "test_files = np.array(test_files)[:,0].tolist()\n",
    "train_files = list(set(onlyfiles) - set(test_files))\n",
    "print(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ef2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_part_array_merge (current_dir, npz_units):\n",
    "    sample_array_lst = []\n",
    "    label_array_lst = []\n",
    "    for npz_unit in npz_units:\n",
    "      loaded = np.load(current_dir + npz_unit)\n",
    "      sample_array_lst.append(loaded['sample'])\n",
    "      label_array_lst.append(loaded['label'])\n",
    "    sample_array = np.dstack(sample_array_lst)\n",
    "    label_array = np.concatenate(label_array_lst)\n",
    "    sample_array = sample_array.transpose(2, 0, 1)\n",
    "    return sample_array, label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd652046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10527, 1, 20)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_norm,Ytrain = load_part_array_merge(mypath,train_files)\n",
    "Xtest_norm,Ytest = load_part_array_merge(mypath,test_files)\n",
    "print(Xtrain_norm.shape)\n",
    "Xtrain_norm = Xtrain_norm[:,0,:]\n",
    "Xtest_norm = Xtest_norm[:,0,:]\n",
    "Ytrain_norm = np.expand_dims((Ytrain)/np.max(Ytrain),1)\n",
    "#Ytrain_norm = (Ytrain)/np.max(Ytrain)\n",
    "Ytest_norm = np.expand_dims((Ytest)/np.max(Ytrain),1)\n",
    "#Ytest_norm = (Ytest)/np.max(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e1f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_units = [11]\n",
    "test_files = [[f for f in onlyfiles if str(test_units[j]) in f ] for j in range(len(test_units))]\n",
    "test_files = np.array(test_files)[:,0].tolist()\n",
    "Xtest11_norm,Ytest11 = load_part_array_merge(mypath,test_files)\n",
    "Xtest11_norm = Xtest11_norm[:,0,:]\n",
    "Ytest11_norm = np.expand_dims((Ytest11)/np.max(Ytrain),1)\n",
    "\n",
    "\n",
    "test_units = [14]\n",
    "test_files = [[f for f in onlyfiles if str(test_units[j]) in f ] for j in range(len(test_units))]\n",
    "test_files = np.array(test_files)[:,0].tolist()\n",
    "Xtest14_norm,Ytest14 = load_part_array_merge(mypath,test_files)\n",
    "Xtest14_norm = Xtest14_norm[:,0,:]\n",
    "Ytest14_norm = np.expand_dims((Ytest14)/np.max(Ytrain),1)\n",
    "\n",
    "\n",
    "test_units = [15]\n",
    "test_files = [[f for f in onlyfiles if str(test_units[j]) in f ] for j in range(len(test_units))]\n",
    "test_files = np.array(test_files)[:,0].tolist()\n",
    "Xtest15_norm,Ytest15 = load_part_array_merge(mypath,test_files)\n",
    "Xtest15_norm = Xtest15_norm[:,0,:]\n",
    "Ytest15_norm = np.expand_dims((Ytest15)/np.max(Ytrain),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fea2a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get calibration curves\n",
    "def get_confidence_interval(y_true, mu, sigma):\n",
    "    alphas = np.linspace(1e-10, 1-1e-10, 1000)\n",
    "    myCI=[]\n",
    "    for myalpha in sorted(alphas):\n",
    "        intervals = scipy.stats.norm.interval(alpha=myalpha, loc=mu, scale=sigma)\n",
    "        lower_bd = intervals[0]\n",
    "        upper_bd = intervals[1]\n",
    "        myCI.append(np.sum((y_true > lower_bd) & (y_true < upper_bd))/len(y_true))\n",
    "    \n",
    "    return 100*alphas, 100*np.array(myCI)  # converting to percentages\n",
    "\n",
    "\n",
    "def get_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    y_true - true values\n",
    "    y_pred - predicted values\n",
    "    Outputs:\n",
    "    root mean squarred error\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((y_true-y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ded88407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC_SNGP(tf.keras.Model):\n",
    "    def __init__(self, no_outputs, spec_norm_bound=0.9, actfn = 'relu', **kwargs):\n",
    "        super().__init__()\n",
    "        self.actfn = actfn\n",
    "        self.spec_norm_bound = spec_norm_bound\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        # hidden layers.\n",
    "        self.dense_layers1 = nlp_layers.SpectralNormalization(self.make_dense_layer(100),\n",
    "                                                              norm_multiplier=self.spec_norm_bound)\n",
    "        self.dense_layers21 = nlp_layers.SpectralNormalization(self.make_dense_layer(100),\n",
    "                                                              norm_multiplier=self.spec_norm_bound)\n",
    "        self.dense_layers22 = nlp_layers.SpectralNormalization(self.make_dense_layer(100),\n",
    "                                                              norm_multiplier=self.spec_norm_bound)\n",
    "        self.dense_layers23 = nlp_layers.SpectralNormalization(self.make_dense_layer(100),\n",
    "                                                              norm_multiplier=self.spec_norm_bound)\n",
    "        self.dense_layers24 = nlp_layers.SpectralNormalization(self.make_dense_layer(100),\n",
    "                                                              norm_multiplier=self.spec_norm_bound)\n",
    "        self.dense_layers3 = nlp_layers.SpectralNormalization(self.make_dense_layer(10),\n",
    "                                                              norm_multiplier=self.spec_norm_bound)\n",
    "        # output layer.\n",
    "        self.regressor = self.make_output_layer(no_outputs)\n",
    "\n",
    "    def call(self, inputs, training=True, return_covmat=False):\n",
    "        x = self.dense_layers1(inputs)\n",
    "#         for _ in range(2):\n",
    "        x = self.dense_layers21(x)\n",
    "        x1 = self.dense_layers22(x)\n",
    "        x = x1 + x\n",
    "        x = self.dense_layers23(x)\n",
    "        x1 = self.dense_layers24(x)\n",
    "        x = x1 + x\n",
    "        x = self.dense_layers3(x)\n",
    "        mean = self.regressor(x)[0]\n",
    "        variance = self.regressor(x)[1]\n",
    "        if not training and return_covmat:\n",
    "            return mean, variance\n",
    "        \n",
    "        return mean\n",
    "\n",
    "    def make_dense_layer(self, hidden_units):\n",
    "        \"\"\"Use the Dense layer as the hidden layer.\"\"\"\n",
    "        return tf.keras.layers.Dense(hidden_units, activation=self.actfn)\n",
    "\n",
    "    def make_output_layer(self, no_outputs):\n",
    "        \"\"\"Uses Gaussian process as the output layer.\"\"\"\n",
    "        return nlp_layers.RandomFeatureGaussianProcess(\n",
    "            no_outputs,\n",
    "            gp_cov_momentum=-1,\n",
    "            gp_kernel_scale_trainable=True,\n",
    "            #gp_output_bias_trainable=True,\n",
    "            num_inducing=100,\n",
    "            gp_kernel_scale=0.0001,\n",
    "            **self.kwargs)\n",
    "\n",
    "class ResetCovarianceCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"Resets covariance matrix at the beginning of the epoch.\"\"\"\n",
    "        if epoch > 0:\n",
    "            self.model.regressor.reset_covariance_matrix()\n",
    "\n",
    "class FC_SNGPWithCovReset(FC_SNGP):\n",
    "    def fit(self, *args, **kwargs):\n",
    "        \"\"\"Adds ResetCovarianceCallback to model callbacks.\"\"\"\n",
    "        kwargs[\"callbacks\"] = list(kwargs.get(\"callbacks\", []))\n",
    "        kwargs[\"callbacks\"].append(ResetCovarianceCallback())\n",
    "        return super().fit(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22243663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trained_SNGPmodel(trainX, trainY, nepochs, actfn = 'sigmoid', spec_norm_bound = 0.9):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    trainX  - training input of shape (samples, num of features)\n",
    "    trainY  - training output of shape (samples, 1)\n",
    "    nepochs - number of epochs\n",
    "    actfn   - activation function\n",
    "    spec_norm_bound - spectral normalization bounds\n",
    "    Outputs:\n",
    "    model   - trained SNGP model\n",
    "    \"\"\"\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-4)\n",
    "\n",
    "    model = FC_SNGPWithCovReset(no_outputs=1, spec_norm_bound = spec_norm_bound, actfn=actfn)\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    model.fit(trainX, trainY, batch_size=10, epochs=nepochs, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2e374c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /local/home/lbiggio/UQ_ML_Review/UQ/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "1053/1053 [==============================] - 6s 3ms/step - loss: 0.0635\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0243\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0170\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0155\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0133\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0135\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0121\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0118\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0121\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0119\n"
     ]
    }
   ],
   "source": [
    "# single run\n",
    "\n",
    "nepochs=10\n",
    "\n",
    "dataset = ['train', 'test', 'test11', 'test14', 'test15']\n",
    "model_SNGP = generate_trained_SNGPmodel(Xtrain_norm, Ytrain_norm, nepochs, 'relu', 0.9)\n",
    "allresults_SNGPdf = pd.DataFrame()\n",
    "for myset in dataset:\n",
    "    exec(\"Xnorm =X\"+myset+\"_norm\")\n",
    "    exec(\"Y =Y\"+myset)\n",
    "\n",
    "    result_df = pd.DataFrame(Y, columns = ['True'])\n",
    "    result_df['dataset'] = myset\n",
    "    result_df[\"SNGP_mu_eff\"] = model_SNGP(Xnorm, training=False, return_covmat=True)[0]\n",
    "    result_df[\"SNGP_sigma_eff\"] = np.sqrt(tf.linalg.diag_part(\n",
    "                                          model_SNGP(Xnorm, training=False, return_covmat=True)[1])[:, None]\n",
    "                                         )\n",
    "    allresults_SNGPdf = pd.concat([allresults_SNGPdf, result_df], axis = 0)\n",
    "\n",
    "allresults_SNGPdf[\"SNGP_mu_eff\"] = allresults_SNGPdf[\"SNGP_mu_eff\"]*(np.max(Ytrain))\n",
    "allresults_SNGPdf[\"SNGP_sigma_eff\"] = allresults_SNGPdf[\"SNGP_sigma_eff\"]*(np.max(Ytrain))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33b75199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  8.447175\n",
      "Test11 RMSE:  7.9605165\n",
      "Test14 RMSE:  9.320882\n",
      "Test15 RMSE:  6.1023655\n"
     ]
    }
   ],
   "source": [
    "print(\"Train RMSE: \", get_rmse(np.array(model_SNGP(Xtrain_norm, training=False,return_covmat=True)[0])[:,0]*(np.max(Ytrain)), Ytrain))\n",
    "print(\"Test11 RMSE: \", get_rmse(np.array(model_SNGP(Xtest11_norm, training=False,return_covmat=True)[0])[:,0]*(np.max(Ytrain)), Ytest11))\n",
    "print(\"Test14 RMSE: \", get_rmse(np.array(model_SNGP(Xtest14_norm, training=False,return_covmat=True)[0])[:,0]*(np.max(Ytrain)), Ytest14))\n",
    "print(\"Test15 RMSE: \", get_rmse(np.array(model_SNGP(Xtest15_norm, training=False,return_covmat=True)[0])[:,0]*(np.max(Ytrain)), Ytest15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee94a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                                                                              |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 4s 3ms/step - loss: 0.1226\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0323\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0237\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0191\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0186\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0162\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0159\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0157\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0147\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% |############                                                                                                                  |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 4s 3ms/step - loss: 0.1583\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.1130\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0975\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0577\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0376\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0277\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0220\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0172\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0162\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% |#########################                                                                                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 4s 3ms/step - loss: 0.1802\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.1049\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0484\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0301\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0220\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0181\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0166\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0158\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0143\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% |#####################################                                                                                         |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 4s 3ms/step - loss: 0.0772\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0226\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0199\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0169\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0152\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0156\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0147\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0145\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0133\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% |##################################################                                                                            |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 4s 3ms/step - loss: 0.1411\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0509\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0234\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0183\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0193\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0162\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0150\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0138\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0147\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% |###############################################################                                                               |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 5s 3ms/step - loss: 0.1075\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0484\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0312\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0231\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0207\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0179\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0170\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0152\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0154\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% |###########################################################################                                                   |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 4s 3ms/step - loss: 0.0996\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0273\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0230\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0204\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0166\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0179\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0158\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0159\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0149\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% |########################################################################################                                      |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 7s 3ms/step - loss: 0.0860\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0298\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 4s 3ms/step - loss: 0.0217\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0181\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0164\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0157\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0158\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 5s 4ms/step - loss: 0.0154\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0138\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% |####################################################################################################                          |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 6s 4ms/step - loss: 0.0637\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0270\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0208\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0190\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0169\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0157\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0156\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0148\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0142\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 4s 4ms/step - loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% |#################################################################################################################             |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 6s 3ms/step - loss: 0.1488\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0342\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0207\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0190\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0181\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0164\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0141\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0147\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 3s 3ms/step - loss: 0.0142\n",
      "Epoch 10/10\n",
      "1042/1053 [============================>.] - ETA: 0s - loss: 0.0129"
     ]
    }
   ],
   "source": [
    "model_train_bool = True\n",
    "if model_train_bool:\n",
    "    nmodels = 1 # total models trained and best one picked\n",
    "    niter = 10\n",
    "\n",
    "    allCI_SNGP = np.zeros((1000, niter))\n",
    "    pbar=ProgressBar()\n",
    "    allresults_SNGPdf = pd.DataFrame()\n",
    "\n",
    "    for myiter in pbar(range(niter)): # for each independent iteration\n",
    "        all_models_SNGP=[]\n",
    "        all_rmse_train_SNGP = np.zeros(nmodels,)\n",
    "        for i in range(nmodels): # train multiple models to select the best\n",
    "            model_SNGP = generate_trained_SNGPmodel(Xtrain_norm, Ytrain_norm, nepochs, 'tanh', 0.9)\n",
    "            all_rmse_train_SNGP[i] = get_rmse(np.array(model_SNGP(Xtrain_norm, training = False, \n",
    "                                                         return_covmat=True)[0])[:,0]*(np.max(Ytrain)), Ytrain)\n",
    "        \n",
    "            all_models_SNGP.append(model_SNGP)\n",
    "        select_modelSNGP = all_models_SNGP[np.argmin(all_rmse_train_SNGP)] # best model\n",
    "\n",
    "             \n",
    "        for myset in dataset:\n",
    "            exec(\"Xnorm =X\"+myset+\"_norm\")\n",
    "            exec(\"Y =Y\"+myset)\n",
    "\n",
    "            result_df = pd.DataFrame(Y, columns = ['True'])\n",
    "            result_df['dataset'] = myset\n",
    "            result_df[\"SNGP_mu_eff\"] = select_modelSNGP(Xnorm, training=False, return_covmat=True)[0]\n",
    "            result_df[\"SNGP_sigma_eff\"] = np.sqrt(tf.linalg.diag_part(\n",
    "                                          select_modelSNGP(Xnorm, training=False, return_covmat=True)[1])[:, None]\n",
    "                                                 )\n",
    "            result_df['iteration'] = myiter\n",
    "            allresults_SNGPdf = pd.concat([allresults_SNGPdf, result_df], axis = 0)\n",
    "               \n",
    "    allresults_SNGPdf[\"SNGP_mu_eff\"] = allresults_SNGPdf[\"SNGP_mu_eff\"]*(np.max(Ytrain))\n",
    "    allresults_SNGPdf[\"SNGP_sigma_eff\"] = allresults_SNGPdf[\"SNGP_sigma_eff\"]*(np.max(Ytrain))\n",
    "    #allresults_SNGPdf.to_excel(\"results/SNGP_battery_prediction_results_new.xlsx\")  \n",
    "else:\n",
    "    allresults_SNGPdf=pd.read_excel(\"results/SNGP_battery_prediction_results.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1465bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the calibration curve\n",
    "allresults_SNGPdf_train = allresults_SNGPdf.loc[allresults_SNGPdf['dataset']=='train']\n",
    "\n",
    "alphas, CI_DE = get_confidence_interval(allresults_SNGPdf_train['True'].values, \n",
    "                                       allresults_SNGPdf_train['SNGP_mu_eff'].values, \n",
    "                                       allresults_SNGPdf_train['SNGP_sigma_eff'].values)\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.plot(alphas,CI_DE, color = 'blue', label='MC Dropout')\n",
    "plt.plot([0,100],[0,100], color='black', linestyle='dashed', label='Ideal')\n",
    "plt.xlabel('Expected Confidence')\n",
    "plt.ylabel('Precited Confidence')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86f1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UQ",
   "language": "python",
   "name": "uq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
